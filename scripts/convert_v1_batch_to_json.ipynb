{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import hashlib\n",
    "import string\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "root_dir = '../Themes'\n",
    "audio_dir = '../audio'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert old type text files into json\n",
    "print(os.listdir(root_dir))\n",
    "\n",
    "for subdir, _, files in os.walk(root_dir):\n",
    "    for file in files:\n",
    "        if file.endswith('.txt'):\n",
    "            output = []\n",
    "            unique_no_sub = set()\n",
    "            unique_sub = set()\n",
    "            theme = os.path.splitext(file)[0]\n",
    "            file_path = os.path.join(subdir, file)\n",
    "            try:\n",
    "                #print(f\"Processing {file_path}...\")\n",
    "                with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                    for line_number, line in enumerate(f, 1):\n",
    "                        line = line.strip()\n",
    "                        if not line or line.startswith('Description:'):\n",
    "                            continue\n",
    "                        parts = line.split('\\t')\n",
    "                        if len(parts) != 4:\n",
    "                            print(f\"Warning: Line {line_number} in {file} does not have 4 columns.\")\n",
    "                            continue\n",
    "                        difficulty, line_no_sub, line_with_sub, dom_flag = parts\n",
    "                        dominant = \"Master\" if dom_flag.lower() == \"dom\" else None\n",
    "                        # Entry without submissive pet name\n",
    "                        if line_no_sub in unique_no_sub:\n",
    "                            print(f\"Warning: Duplicate entry found in {file}: {line_no_sub}\")\n",
    "                        else:\n",
    "                            entry_no_sub = {\n",
    "                                \"type\": \"audio\",\n",
    "                                \"line\": line_no_sub,\n",
    "                                \"theme\": theme,\n",
    "                                \"dominant\": dominant,\n",
    "                                \"subject\": None,\n",
    "                                \"difficulty\": difficulty\n",
    "                            }\n",
    "                            output.append(entry_no_sub)\n",
    "                            unique_no_sub.add(line_no_sub)\n",
    "                        if line_with_sub in unique_sub:\n",
    "                            print(f\"Warning: Duplicate entry found in {file}: {line_with_sub}\")\n",
    "                        else:\n",
    "                            # Entry with submissive pet name\n",
    "                            entry_with_sub = {\n",
    "                                \"type\": \"audio\",\n",
    "                                \"line\": line_with_sub,\n",
    "                                \"theme\": theme,\n",
    "                                \"dominant\": dominant,\n",
    "                                \"subject\": \"Bambi\",\n",
    "                                \"difficulty\": difficulty\n",
    "                            }\n",
    "                            output.append(entry_with_sub)\n",
    "                            unique_sub.add(line_with_sub)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {file}: {e}\")\n",
    "            if output:\n",
    "                with open(os.path.join(subdir,f'{theme}.json'), 'w', encoding='utf-8') as outfile:\n",
    "                    json.dump(output, outfile, ensure_ascii=False, indent=4)\n",
    "            else:\n",
    "                print(f\"No valid entries found in {file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is 974 lines\n",
      "Deduplicate is 974\n",
      "Data is 814 lines\n",
      "Deduplicate is 814\n",
      "Data is 820 lines\n",
      "Deduplicate is 820\n",
      "Data is 886 lines\n",
      "Deduplicate is 886\n",
      "Data is 900 lines\n",
      "Deduplicate is 900\n",
      "Data is 876 lines\n",
      "Deduplicate is 876\n",
      "Data is 898 lines\n",
      "Deduplicate is 898\n",
      "Data is 856 lines\n",
      "Deduplicate is 856\n",
      "Data is 1026 lines\n",
      "Deduplicate is 1026\n",
      "Data is 900 lines\n",
      "Deduplicate is 900\n",
      "Data is 748 lines\n",
      "Deduplicate is 748\n",
      "Data is 862 lines\n",
      "duplicate line: Bambi's approval is her strongest motivation.\n",
      "Deduplicate is 861\n",
      "Data is 862 lines\n",
      "Deduplicate is 862\n"
     ]
    }
   ],
   "source": [
    "# convert any lines including \"Master\" to \"Mistress\" and append to original json\n",
    "for subdir, _, files in os.walk(root_dir):\n",
    "    for file in files:\n",
    "        if file.endswith('.json'):\n",
    "            file_path = os.path.join(subdir, file)\n",
    "            try:\n",
    "                with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                    data = json.load(f)\n",
    "                    for entry in data:\n",
    "                        line = entry.get('line', '')\n",
    "                        if entry['dominant']==\"Master\":\n",
    "                            new_entry = entry.copy() #note, this would probably break if the subject has gendered pronouns. probably better to stay neutral they/them for consistency\n",
    "                            new_entry['line'] = re.sub(r'\\bmaster\\b', 'Mistress', line, flags=re.IGNORECASE)\n",
    "                            new_entry['line'] = re.sub(r'\\bhis\\b', 'her', new_entry['line'], flags=re.IGNORECASE)\n",
    "                            new_entry['line'] = re.sub(r'\\bhe\\b', 'she', new_entry['line'], flags=re.IGNORECASE)\n",
    "                            new_entry['line'] = re.sub(r'\\bhim\\b', 'her', new_entry['line'], flags=re.IGNORECASE)\n",
    "                            new_entry['dominant']=\"Mistress\"\n",
    "                            data.append(new_entry)\n",
    "                    #print([i for i in data if i['dominant']=='Mistress'])\n",
    "                    # for i in data:\n",
    "                    #     if i['dominant']==\"Mistress\":\n",
    "                    #         print(i['line'])\n",
    "                #do a simple deduplication of data by making sure data[n]['line'] is unique\n",
    "                print(f\"Data is {len(data)} lines\")\n",
    "                seen = set()\n",
    "                deduplicated_data = []\n",
    "                for item in data:\n",
    "                    if item['line'] not in seen:\n",
    "                        deduplicated_data.append(item)\n",
    "                        seen.add(item['line'])\n",
    "                    else:\n",
    "                        print(\"duplicate line: \" + item['line'])\n",
    "                print(f\"Deduplicate is {len(deduplicated_data)}\")\n",
    "                with open(file_path, 'w', encoding='utf-8') as f:\n",
    "                    json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {file}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polly = boto3.client('polly')\n",
    "\n",
    "os.makedirs(audio_dir, exist_ok=True)\n",
    "\n",
    "processed_lines = set()\n",
    "# Include existing mp3 files in processed_lines\n",
    "for filename in os.listdir(audio_dir):\n",
    "    if filename.endswith('.mp3'):\n",
    "        file_root = os.path.splitext(filename)[0]  # Remove file extension\n",
    "        processed_lines.add(file_root)\n",
    "\n",
    "for subdir, _, files in os.walk(root_dir):\n",
    "    for file in files:\n",
    "        if file.endswith('.json'):\n",
    "            new_entries = 0\n",
    "            file_path = os.path.join(subdir, file)\n",
    "            theme = os.path.splitext(file)[0]\n",
    "            try:\n",
    "                with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                    data = json.load(f)\n",
    "                    for entry in data:\n",
    "                        line = entry.get('line', '')\n",
    "                        # Normalize the line to create a unique key\n",
    "                        line_key = line.translate(str.maketrans('', '', string.punctuation)).replace(' ', '').lower()\n",
    "                        line_hash = hashlib.sha256(line_key.encode('utf-8')).hexdigest()\n",
    "                        if line_hash in processed_lines:\n",
    "                            continue\n",
    "                        response = polly.synthesize_speech(\n",
    "                            Text=line,\n",
    "                            OutputFormat='mp3',\n",
    "                            VoiceId='Salli'  # Standard voice, not neural\n",
    "                        )\n",
    "                        new_entries += 1\n",
    "                        audio_file_path = os.path.join(audio_dir, f\"{line_hash}.mp3\")\n",
    "                        with open(audio_file_path, 'wb') as audio_file:\n",
    "                            audio_file.write(response['AudioStream'].read())\n",
    "                        processed_lines.add(line_hash)\n",
    "                if new_entries:\n",
    "                    print(f\"Processed: {theme} with {new_entries} new entries\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {file}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orphaned_lines = []\n",
    "\n",
    "for subdir, _, files in os.walk(root_dir):\n",
    "    for file in files:\n",
    "        if file.endswith('.json'):\n",
    "            file_path = os.path.join(subdir, file)\n",
    "            try:\n",
    "                with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                    data = json.load(f)\n",
    "                    for entry in data:\n",
    "                        line = entry.get('line', '')\n",
    "                        if not line:\n",
    "                            orphaned_lines.append({'file': file, 'entry': entry, 'reason': 'Missing line'})\n",
    "                            continue\n",
    "                        # Generate line hash as before\n",
    "                        line_key = line.translate(str.maketrans('', '', string.punctuation)).replace(' ', '').lower()\n",
    "                        line_hash = hashlib.sha256(line_key.encode('utf-8')).hexdigest()\n",
    "                        if line_hash not in processed_lines:\n",
    "                            orphaned_lines.append({'file': file, 'line': line, 'reason': 'No audio associated'})\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {file}: {e}\")\n",
    "\n",
    "if orphaned_lines:\n",
    "    print(\"The following entries are orphaned:\")\n",
    "    for orphan in orphaned_lines:\n",
    "        print(f\"File: {orphan['file']}, Line: {orphan.get('line', '')}, Reason: {orphan['reason']}\")\n",
    "else:\n",
    "    print(\"No orphaned or abandoned lines found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
